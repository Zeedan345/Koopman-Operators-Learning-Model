{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dfecc71-1844-4954-937a-c594b8ace5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e58358-35f2-4b9d-955d-54c6e7081717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lorenz(initial_state, steps = 500, dt= 0.01, sigma = 10.0, rho = 28.0, beta = 8.0/3.0):\n",
    "    def lorenz_system(state):\n",
    "        x, y, z = state\n",
    "        dxdt = sigma * (y - x)\n",
    "        dydt = x * (rho - z) - y\n",
    "        dzdt = x * y - beta * z\n",
    "        return np.array([dxdt, dydt, dzdt])\n",
    "    state = np.array(initial_state)\n",
    "    trajectory = []\n",
    "    for _ in range(steps):\n",
    "        trajectory.append(state.copy())\n",
    "        k1 = lorenz_system(state)\n",
    "        k2 = lorenz_system(state + 0.5 * dt * k1)\n",
    "        k3 = lorenz_system(state + 0.5 * dt * k2)\n",
    "        k4 = lorenz_system(state + dt * k3)\n",
    "        state += (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "    return np.array(trajectory)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb8264d-cece-419c-8303-29b614698d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_lorenz(trajectory):\n",
    "    edge_index = []\n",
    "    for i in range(len(trajectory)-1):\n",
    "        edge_index.append([i, i+1])\n",
    "    edge_index = torch.tensor(edge_index, dtype = torch.long).t().contiguous()\n",
    "    x = torch.tensor(trajectory, dtype = torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index = edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1100bb35-c769-437a-9f98-75ebac0923e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def create_full_graph(self, x):\n",
    "        n = x.size(0)\n",
    "        edge_index = torch.stack([\n",
    "            torch.repeat_interleave(torch.arange(n), n),\n",
    "            torch.tile(torch.arange(n), (n,))\n",
    "        ]).to(x.device)\n",
    "        return edge_index\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = x.float()\n",
    "        edge_index = self.create_full_graph(x)\n",
    "        gnn_x = self.conv1(x, edge_index).relu()\n",
    "        gnn_x = self.norm1(gnn_x)\n",
    "        gnn_x = self.conv2(gnn_x, edge_index)\n",
    "        gnn_x = self.norm2(gnn_x)\n",
    "\n",
    "        fc_x = self.fc1(x).relu()\n",
    "        fc_x = self.fc3(fc_x).relu()\n",
    "        fc_x = self.fc3(fc_x)\n",
    "\n",
    "        return (gnn_x+ fc_x)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b11eb441-3291-47fc-a4e7-65efaf8d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoopmanModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, koopman_dim):\n",
    "        super(KoopmanModel, self).__init__()\n",
    "        self.encoder = GNN(input_dim, koopman_dim, koopman_dim)\n",
    "        self.koopman_matrix = torch.nn.Parameter(torch.eye(koopman_dim))\n",
    "        self.decoder = GNN(koopman_dim, koopman_dim, input_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        koopman_space = self.encoder(data)\n",
    "        next_koopman_space = koopman_space @ self.koopman_matrix\n",
    "        new_data = Data(x=next_koopman_space, edge_index = data.edge_index)\n",
    "        new_state = self.decoder(new_data)\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "962089ed-41fe-4669-aace-d8c38abdcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoding_loss(decoded, original_states):\n",
    "    return F.mse_loss(decoded, original_states)\n",
    "\n",
    "def prediction_loss(model, koopman_space, data):\n",
    "    g_t = koopman_space\n",
    "    T = len(data.x)\n",
    "    total_pred_loss = 0\n",
    "    for t in range(T):\n",
    "        decoded_state = model.decoder(Data(x=g_t, edge_index = data.edge_index))\n",
    "        total_pred_loss += F.mse_loss(decoded_state, data.x)\n",
    "        if(t < T-1):\n",
    "            g_t = g_t @ model.koopman_matrix\n",
    "    \n",
    "    return total_pred_loss / T\n",
    "\n",
    "def metric_loss(koopman_space, original_space):\n",
    "    distances_koopman = torch.cdist(koopman_space, koopman_space, p=2)\n",
    "    distances_original = torch.cdist(original_space, original_space, p=2)\n",
    "    return F.l1_loss(distances_koopman, distances_original)\n",
    "\n",
    "\n",
    "def total_loss(model, data, lambda1=1.0, lambda2=1.0):\n",
    "    koopman_space = model.encoder(data)\n",
    "    decoded = model.decoder(Data(x=koopman_space, edge_index=data.edge_index))\n",
    "    \n",
    "    ae_loss = auto_encoding_loss(decoded, data.x)\n",
    "    pred_loss = prediction_loss(model, koopman_space, data)\n",
    "    m_loss = metric_loss(koopman_space, data.x)\n",
    "    print(f\"AE Loss: {ae_loss}, Prediction Loss {pred_loss}, Total Loss {m_loss}\")\n",
    "\n",
    "    return ae_loss + lambda1 * pred_loss + lambda2 * m_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb9126e3-b1c9-4731-8f41-274aae01e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs=10, lambda1=1.0, lambda2=1.0, batch_size=8):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    train_losses = []\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            loss = total_loss(model, batch, lambda1=lambda1, lambda2=lambda2)\n",
    "            if not torch.isnan(loss): \n",
    "                loss.backward()  \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "        if batch_count > 0:\n",
    "            avg_loss = epoch_loss / batch_count\n",
    "            train_losses.append(avg_loss)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.6f}\")\n",
    "            scheduler.step(avg_loss)  \n",
    "        else:\n",
    "            print(f\"Warning: Epoch {epoch + 1} had no valid batches!\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_losses)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0496e37-4563-4763-a115-49d713a4100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [1.0, 0.0, 0.0]\n",
    "lorenz_trajectory = simulate_lorenz(initial_state)\n",
    "dataset = [create_graph_lorenz(lorenz_trajectory) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd69b7b-3319-4a5d-9d51-e7a50909fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KoopmanModel(input_dim = 3, koopman_dim = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae94b78-320b-41be-aa94-474914a46942",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, dataset, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b16baa-71b8-4073-ae3f-6c571b6b9f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d434c-305e-4575-b1cf-c168df967cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
