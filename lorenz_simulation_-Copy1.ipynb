{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfecc71-1844-4954-937a-c594b8ace5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e58358-35f2-4b9d-955d-54c6e7081717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lorenz(initial_state, steps = 200, dt= 0.01, sigma = 10.0, rho = 28.0, beta = 8.0/3.0):\n",
    "    def lorenz_system(state):\n",
    "        x, y, z = state\n",
    "        dxdt = sigma * (y - x)\n",
    "        dydt = x * (rho - z) - y\n",
    "        dzdt = x * y - beta * z\n",
    "        return np.array([dxdt, dydt, dzdt])\n",
    "    state = np.array(initial_state)\n",
    "    trajectory = []\n",
    "    for _ in range(steps):\n",
    "        trajectory.append(state.copy())\n",
    "        k1 = lorenz_system(state)\n",
    "        k2 = lorenz_system(state + 0.5 * dt * k1)\n",
    "        k3 = lorenz_system(state + 0.5 * dt * k2)\n",
    "        k4 = lorenz_system(state + dt * k3)\n",
    "        state += (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "    return np.array(trajectory)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb8264d-cece-419c-8303-29b614698d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_lorenz(trajectory):\n",
    "    edge_index = []\n",
    "    for i in range(len(trajectory)-1):\n",
    "        edge_index.append([i, i+1])\n",
    "    edge_index = torch.tensor(edge_index, dtype = torch.long).t().contiguous()\n",
    "    x = torch.tensor(trajectory, dtype = torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index = edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1100bb35-c769-437a-9f98-75ebac0923e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)  \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def create_full_graph(self, x):\n",
    "        n = x.size(0)\n",
    "        edge_index = torch.stack([\n",
    "            torch.repeat_interleave(torch.arange(n), n),\n",
    "            torch.tile(torch.arange(n), (n,))\n",
    "        ]).to(x.device)\n",
    "        return edge_index\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = x.float()\n",
    "        edge_index = self.create_full_graph(x)\n",
    "        \n",
    "        # GNN path\n",
    "        gnn_x = self.conv1(x, edge_index).relu()\n",
    "        gnn_x = self.norm1(gnn_x)\n",
    "        gnn_x = self.conv2(gnn_x, edge_index)\n",
    "        gnn_x = self.norm2(gnn_x)\n",
    "\n",
    "        # FC path - fixed the layer usage\n",
    "        fc_x = self.fc1(x).relu()\n",
    "        fc_x = self.fc2(fc_x).relu() \n",
    "        fc_x = self.fc3(fc_x)         \n",
    "\n",
    "        return (gnn_x + fc_x)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0742c1b0-6d18-4e0c-adb1-a3e4fc2ceaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedKoopmanModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, koopman_dim, hidden_dim=32):\n",
    "        super(AdvancedKoopmanModel, self).__init__()\n",
    "        self.encoder = GNN(input_dim, hidden_dim, koopman_dim)\n",
    "        self.decoder = GNN(koopman_dim, hidden_dim, input_dim)\n",
    "        init_matrix = torch.zeros(koopman_dim, koopman_dim)\n",
    "        for i in range(0, koopman_dim-1, 2):\n",
    "            init_matrix[i:i+2, i:i+2] = torch.tensor([[0., -1.], [1., 0.]])\n",
    "        self.koopman_matrix = torch.nn.Parameter(init_matrix)\n",
    "        \n",
    "        self.register_buffer('running_mean', torch.zeros(input_dim))\n",
    "        self.register_buffer('running_std', torch.ones(input_dim))\n",
    "        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "\n",
    "    def update_statistics(self, x):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                batch_mean = x.mean(dim=0)\n",
    "                batch_std = x.std(dim=0)\n",
    "                \n",
    "                if self.num_batches_tracked == 0:\n",
    "                    self.running_mean = batch_mean\n",
    "                    self.running_std = batch_std\n",
    "                else:\n",
    "                    momentum = 0.1\n",
    "                    self.running_mean = (1 - momentum) * self.running_mean + momentum * batch_mean\n",
    "                    self.running_std = (1 - momentum) * self.running_std + momentum * batch_std\n",
    "                \n",
    "                self.num_batches_tracked += 1\n",
    "\n",
    "    def metric_loss(self, g, states, split_size=2):\n",
    "        batch_size = g.size(0)\n",
    "        permu = torch.randperm(batch_size)\n",
    "        split_0 = permu[:batch_size//split_size]\n",
    "        split_1 = permu[batch_size//split_size:2*(batch_size//split_size)]\n",
    "        dist_g = torch.mean((g[split_0] - g[split_1]) ** 2, dim=1)\n",
    "        dist_s = torch.mean((states[split_0] - states[split_1]) ** 2, dim=1)\n",
    "        \n",
    "        scaling_factor = 10.0\n",
    "        return torch.abs(dist_g * scaling_factor - dist_s).mean()\n",
    "\n",
    "    def system_identify(self, G, H, regularization=0.1):\n",
    "        batch_size = G.size(0)\n",
    "        I = torch.eye(self.koopman_matrix.size(0)).to(G.device)\n",
    "        A = torch.matmul(H.transpose(1, 2), G) @ torch.inverse(\n",
    "            torch.matmul(G.transpose(1, 2), G) + regularization * I\n",
    "        )\n",
    "        return A\n",
    "\n",
    "    def forward(self, data):\n",
    "        self.update_statistics(data.x)\n",
    "        koopman_space = self.encoder(data)\n",
    "        next_koopman_space = koopman_space @ self.koopman_matrix\n",
    "        new_data = Data(x=next_koopman_space, edge_index=data.edge_index)\n",
    "        decoded_state = self.decoder(new_data)\n",
    "        \n",
    "        return decoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962089ed-41fe-4669-aace-d8c38abdcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_loss(model, data, pred, lambda_metric=0.1, lambda_reg=0.01):\n",
    "    recon_loss = F.mse_loss(pred, data.x)\n",
    "    metric_loss = model.metric_loss(model.encoder(data), data.x)\n",
    "    reg_loss = lambda_reg * torch.norm(model.koopman_matrix)\n",
    "    \n",
    "    return recon_loss + lambda_metric * metric_loss + reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfb5b3e-9082-481c-b976-c419b886555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_advanced_model(model, dataset, epochs=50, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(data)\n",
    "            \n",
    "            loss = advanced_loss(model, data, pred)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataset)\n",
    "        scheduler.step(avg_loss)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfd7776-1d19-4eff-acb8-a1e78016990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdvancedKoopmanModel(input_dim=3, koopman_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9de336-7b0b-437e-af4a-22f04b3b5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for _ in range(100): \n",
    "    initial_state = [\n",
    "        np.random.normal(1.0, 0.2),\n",
    "        np.random.normal(0.0, 0.2),\n",
    "        np.random.normal(0.0, 0.2)\n",
    "    ]\n",
    "    trajectory = simulate_lorenz(initial_state, steps=1000, dt=0.01) \n",
    "    data = create_graph_lorenz(trajectory)\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "95196254-b0f6-443f-b424-4274a3a1ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 148.247553\n",
      "Epoch 1, Loss: 2.935909\n",
      "Epoch 2, Loss: 0.686900\n",
      "Epoch 3, Loss: 0.423208\n",
      "Epoch 4, Loss: 0.274925\n",
      "Epoch 5, Loss: 0.232765\n",
      "Epoch 6, Loss: 0.210570\n",
      "Epoch 7, Loss: 0.201241\n",
      "Epoch 8, Loss: 0.185007\n",
      "Epoch 9, Loss: 0.172650\n",
      "Epoch 10, Loss: 0.156881\n",
      "Epoch 11, Loss: 0.129595\n",
      "Epoch 12, Loss: 0.104744\n",
      "Epoch 13, Loss: 0.092362\n",
      "Epoch 14, Loss: 0.084623\n",
      "Epoch 15, Loss: 0.084972\n",
      "Epoch 16, Loss: 0.084832\n",
      "Epoch 17, Loss: 0.081375\n",
      "Epoch 18, Loss: 0.078147\n",
      "Epoch 19, Loss: 0.076628\n",
      "Epoch 20, Loss: 0.074552\n",
      "Epoch 21, Loss: 0.073555\n",
      "Epoch 22, Loss: 0.073847\n",
      "Epoch 23, Loss: 0.072256\n",
      "Epoch 24, Loss: 0.077164\n",
      "Epoch 25, Loss: 0.071699\n",
      "Epoch 26, Loss: 0.074641\n",
      "Epoch 27, Loss: 0.075953\n",
      "Epoch 28, Loss: 0.066800\n",
      "Epoch 29, Loss: 0.074167\n",
      "Epoch 30, Loss: 0.066932\n",
      "Epoch 31, Loss: 0.071477\n",
      "Epoch 32, Loss: 0.068727\n",
      "Epoch 33, Loss: 0.065635\n",
      "Epoch 34, Loss: 0.066251\n",
      "Epoch 35, Loss: 0.066057\n",
      "Epoch 36, Loss: 0.073897\n",
      "Epoch 37, Loss: 0.062618\n",
      "Epoch 38, Loss: 0.063868\n",
      "Epoch 39, Loss: 0.066236\n",
      "Epoch 40, Loss: 0.063772\n",
      "Epoch 41, Loss: 0.066838\n",
      "Epoch 42, Loss: 0.066541\n",
      "Epoch 43, Loss: 0.061561\n",
      "Epoch 44, Loss: 0.066863\n",
      "Epoch 45, Loss: 0.061767\n",
      "Epoch 46, Loss: 0.061397\n",
      "Epoch 47, Loss: 0.061145\n",
      "Epoch 48, Loss: 0.060855\n",
      "Epoch 49, Loss: 0.059160\n"
     ]
    }
   ],
   "source": [
    "losses = train_advanced_model(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b16baa-71b8-4073-ae3f-6c571b6b9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4929aa42-95bc-40f5-94d3-e0a796ca0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"lorenz-koopman-models\"\n",
    "os.makedirs(save_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71ce7d3b-c8d8-4498-b455-e5aa29d82ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(save_folder, \"lorenz-koopman-model-3.5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "90a79dcb-aed8-4941-86b2-e175ac42e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lorenz-koopman-models\\lorenz-koopman-model-3.5.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f49e2dd-e016-4c7f-a9dc-a6fa8eeec7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdvancedKoopmanModel(\n",
       "  (encoder): GNN(\n",
       "    (fc1): Linear(in_features=3, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (conv1): GCNConv(3, 32)\n",
       "    (conv2): GCNConv(32, 16)\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): GNN(\n",
       "    (fc1): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=3, bias=True)\n",
       "    (conv1): GCNConv(16, 32)\n",
       "    (conv2): GCNConv(32, 3)\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdvancedKoopmanModel(input_dim=3, koopman_dim=16).to(device)\n",
    "model.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cbee76b-8683-422c-9c1e-184d1135e061",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.29 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 2.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 14\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m model(test_data)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     15\u001b[0m     actual \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create the visualization\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m, in \u001b[0;36mAdvancedKoopmanModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_statistics(data\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m---> 52\u001b[0m     koopman_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(data)\n\u001b[0;32m     53\u001b[0m     next_koopman_space \u001b[38;5;241m=\u001b[39m koopman_space \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkoopman_matrix\n\u001b[0;32m     54\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39mnext_koopman_space, edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_full_graph(x)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# GNN path\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m gnn_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[0;32m     30\u001b[0m gnn_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(gnn_x)\n\u001b[0;32m     31\u001b[0m gnn_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(gnn_x, edge_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_sa445z_k.py:209\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[0;32m    200\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    201\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m                 edge_weight\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_weight\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[0;32m    206\u001b[0m             )\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\n\u001b[0;32m    210\u001b[0m     x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[0;32m    211\u001b[0m     edge_weight\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39medge_weight,\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:271\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[1;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m edge_weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x_j\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.29 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 2.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Get the first trajectory from dataset\n",
    "# test_data = dataset[74].to(device)\n",
    "\n",
    "initial_state = [\n",
    "    np.random.normal(1.0, 0.2),\n",
    "    np.random.normal(0.0, 0.2),\n",
    "    np.random.normal(0.0, 0.2)\n",
    "]\n",
    "trajectory = simulate_lorenz(initial_state, steps=6000, dt=0.01) \n",
    "test_data = create_graph_lorenz(trajectory).to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predicted = model(test_data).cpu().numpy()\n",
    "    actual = test_data.x.cpu().numpy()\n",
    "\n",
    "# Create the visualization\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 3D trajectory plot\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot(actual[:, 0], actual[:, 1], actual[:, 2], \n",
    "         'b-', label='Actual', alpha=0.7)\n",
    "ax1.plot(predicted[:, 0], predicted[:, 1], predicted[:, 2], \n",
    "         'r--', label='Predicted', alpha=0.7)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('3D Trajectory Comparison')\n",
    "ax1.legend()\n",
    "\n",
    "# Time series plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "time = np.arange(len(actual))\n",
    "ax2.plot(time, actual[:, 0], 'b-', label='Actual X', alpha=0.7)\n",
    "ax2.plot(time, predicted[:, 0], 'r--', label='Predicted X', alpha=0.7)\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('X Coordinate')\n",
    "ax2.set_title('X Coordinate Time Series')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"Actual trajectory range:\", \n",
    "      np.min(actual, axis=0), \n",
    "      np.max(actual, axis=0))\n",
    "print(\"Predicted trajectory range:\", \n",
    "      np.min(predicted, axis=0), \n",
    "      np.max(predicted, axis=0))\n",
    "\n",
    "# Calculate and print error metrics\n",
    "mse = np.mean((actual - predicted) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(actual - predicted))\n",
    "print(\"\\nError Metrics:\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df4820-0f5f-4928-ba10-e4fbb52b4507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
